{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TitanicFromTs.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNaI69Lh4qkAdyjiCobb+0h"},"kernelspec":{"name":"python3","display_name":"Python 3.6.9 64-bit","metadata":{"interpreter":{"hash":"4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"}}}},"cells":[{"cell_type":"code","metadata":{"id":"gzn0iOeZfTSp"},"source":["# -*- coding: utf-8 -*-\n","# Tensorflow 2.x\n","\n","import random\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"cANijBXtgBO8"},"source":["from sklearn.model_selection import train_test_split\r\n","from sklearn.feature_extraction import DictVectorizer\r\n","from sklearn import preprocessing"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"id":"fkOhcfJnN-Cx","executionInfo":{"status":"error","timestamp":1612847890077,"user_tz":-540,"elapsed":723,"user":{"displayName":"Kotaro Ko","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAyUOZBDxtURc4nVZqv-jNV03CxzI4Dwr1H-4K=s64","userId":"05265138308082330382"}},"outputId":"f1a73fdd-164c-4efe-e1b5-96f682cf333a","tags":[]},"source":["train = pd.read_csv('./data/train.csv')\n","test = pd.read_csv('./data/test.csv')\n","\n","def extract_cabin_type(x):\n","  cabin = x['Cabin']\n","  if isinstance(cabin, str) and cabin[0] != 'T':\n","    return cabin[0]\n","  else:\n","    return np.nan   \n","train['CabinType'] = train.apply(extract_cabin_type, axis=1)\n","test['CabinType'] = test.apply(extract_cabin_type, axis=1)\n","\n","def male_female_child(x):\n","  age = x['Age']\n","  sex = x['Sex']\n","  if age <= 15:\n","    return 'child'\n","  else:\n","    return sex\n","train['PersonType'] = train.apply(male_female_child,axis=1)\n","test['PersonType'] = test.apply(male_female_child,axis=1)\n","\n","\n","#データ整形 train\n","train[\"Embarked\"] = train[\"Embarked\"].replace(\"C\", 0).replace(\"Q\", 1).replace(\"S\", 2)\n","train[\"CabinType\"] = train[\"CabinType\"].replace(\"A\", 0).replace(\"B\", 1).replace(\"C\", 2).replace(\"D\", 3).replace(\"E\", 4).replace(\"F\", 5).replace(\"G\", 6)\n","train[\"Sex\"] = train[\"Sex\"].replace(\"male\", 0).replace(\"female\", 1)\n","train[\"PersonType\"] = train[\"PersonType\"].replace(\"male\", 0).replace(\"female\", 1).replace(\"child\", 2)\n","\n","#データ整形 test\n","test[\"Embarked\"] = test[\"Embarked\"].replace(\"C\", 0).replace(\"Q\", 1).replace(\"S\", 2)\n","test[\"CabinType\"] = test[\"CabinType\"].replace(\"A\", 0).replace(\"B\", 1).replace(\"C\", 2).replace(\"D\", 3).replace(\"E\", 4).replace(\"F\", 5).replace(\"G\", 6)\n","test[\"Sex\"] = test[\"Sex\"].replace(\"male\", 0).replace(\"female\", 1)\n","test[\"PersonType\"] = test[\"PersonType\"].replace(\"male\", 0).replace(\"female\", 1).replace(\"child\", 2)\n","\n","#データ補完\n","train[\"Embarked\"] = train[\"Embarked\"].fillna(2)\n","train[\"CabinType\"] = train[\"CabinType\"].fillna(-1)\n","age_mean = pd.concat([train[\"Age\"], test[\"Age\"]]).mean()\n","fare_mean = pd.concat([train[\"Fare\"], test[\"Fare\"]]).mean()\n","train[\"Age\"] = train[\"Age\"].fillna(age_mean)\n","train[\"Fare\"] = train[\"Fare\"].fillna(fare_mean)\n","\n","test[\"Embarked\"] = test[\"Embarked\"].fillna(2)\n","test[\"CabinType\"] = test[\"CabinType\"].fillna(-1)\n","test[\"Age\"] = test[\"Age\"].fillna(age_mean)\n","test[\"Fare\"] = test[\"Fare\"].fillna(fare_mean)\n","\n","# Cabin は使わない。\n","print('訓練データの欠損値の個数\\n', train.isnull().sum())\n","print('-' * 40)\n","print('テストデータの欠損値の個数\\n', test.isnull().sum())"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["訓練データの欠損値の個数\n PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge              0\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         0\nCabinType        0\nPersonType       0\ndtype: int64\n----------------------------------------\nテストデータの欠損値の個数\n PassengerId      0\nPclass           0\nName             0\nSex              0\nAge              0\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          327\nEmbarked         0\nCabinType        0\nPersonType       0\ndtype: int64\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"tags":[]},"outputs":[],"source":["# トレーニングデータ\n","x_spl = train.loc[:, ['Age', 'Pclass', 'PersonType', 'SibSp', 'Parch', 'Fare', 'CabinType', 'Embarked']].values\n","x_t = train.loc[:, ['Age', 'Pclass', 'PersonType', 'SibSp', 'Parch', 'Fare', 'CabinType', 'Embarked']].values\n","y_spl = train.loc[:, ['Survived']].values\n","\n","x_train, x_test, y_train, y_test = train_test_split(x_spl, y_spl, test_size=0.25,random_state=32)\n","# print(x_train)\n","# print(y_train)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","from keras.utils import np_utils\n","from keras.layers.core import Dropout\n","from keras.layers.normalization import BatchNormalization\n","\n","\n","# Network Parameters\n","n_hidden_1 = 64      # 隠れ層1のユニットの数\n","n_hidden_2 = 64      # 隠れ層2のユニットの数\n","n_input = x_train[0:1].size          # 与える変数の数\n","n_classes = 2        # 分類するクラスの数 今回は生き残ったか否かなので2\n","dropout=0.5\n","act=\"relu\"\n","opt=\"adam\"\n","\n","model = Sequential()\n","\n","# 隠れ層1\n","model.add(Dense(input_dim=n_input, units=n_hidden_1))\n","model.add(BatchNormalization())\n","model.add(Activation(act))\n","model.add(Dropout(dropout))\n","# 隠れ層2\n","model.add(Dense(units=n_hidden_２))\n","model.add(BatchNormalization())\n","model.add(Activation(act))\n","model.add(Dropout(dropout))\n","# 出力層\n","model.add(Dense(units=1))\n","model.add(Activation(\"sigmoid\"))\n","model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":6,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","42/42 - 1s - loss: 0.7249 - accuracy: 0.5868\n","Epoch 2/25\n","42/42 - 0s - loss: 0.6770 - accuracy: 0.6362\n","Epoch 3/25\n","42/42 - 0s - loss: 0.6936 - accuracy: 0.6497\n","Epoch 4/25\n","42/42 - 0s - loss: 0.6774 - accuracy: 0.6632\n","Epoch 5/25\n","42/42 - 0s - loss: 0.6710 - accuracy: 0.6557\n","Epoch 6/25\n","42/42 - 0s - loss: 0.6457 - accuracy: 0.6841\n","Epoch 7/25\n","42/42 - 0s - loss: 0.6331 - accuracy: 0.6632\n","Epoch 8/25\n","42/42 - 0s - loss: 0.6264 - accuracy: 0.6901\n","Epoch 9/25\n","42/42 - 0s - loss: 0.5855 - accuracy: 0.6961\n","Epoch 10/25\n","42/42 - 0s - loss: 0.5846 - accuracy: 0.6931\n","Epoch 11/25\n","42/42 - 0s - loss: 0.5813 - accuracy: 0.7081\n","Epoch 12/25\n","42/42 - 0s - loss: 0.5744 - accuracy: 0.7036\n","Epoch 13/25\n","42/42 - 0s - loss: 0.5535 - accuracy: 0.7216\n","Epoch 14/25\n","42/42 - 0s - loss: 0.5768 - accuracy: 0.7111\n","Epoch 15/25\n","42/42 - 0s - loss: 0.5515 - accuracy: 0.7246\n","Epoch 16/25\n","42/42 - 0s - loss: 0.5541 - accuracy: 0.7111\n","Epoch 17/25\n","42/42 - 0s - loss: 0.5656 - accuracy: 0.7470\n","Epoch 18/25\n","42/42 - 0s - loss: 0.5280 - accuracy: 0.7455\n","Epoch 19/25\n","42/42 - 0s - loss: 0.5250 - accuracy: 0.7500\n","Epoch 20/25\n","42/42 - 0s - loss: 0.5621 - accuracy: 0.7305\n","Epoch 21/25\n","42/42 - 0s - loss: 0.5242 - accuracy: 0.7440\n","Epoch 22/25\n","42/42 - 0s - loss: 0.5269 - accuracy: 0.7620\n","Epoch 23/25\n","42/42 - 0s - loss: 0.5268 - accuracy: 0.7455\n","Epoch 24/25\n","42/42 - 0s - loss: 0.5130 - accuracy: 0.7650\n","Epoch 25/25\n","42/42 - 0s - loss: 0.5248 - accuracy: 0.7545\n"]}],"source":["# 学習\n","fit = model.fit(x_train.astype('float32'), y_train.astype('float32'), epochs=25, batch_size=16, verbose=2)\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-80ceb6c4ada1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'titanic_res.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    357\u001b[0m                     \u001b[0;34m\"only Series and DataFrame objs are valid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 )\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"]}],"source":["y_test_proba = model.predict(x_test)\n","y_tmp = np.round(y_test_proba).astype(int)\n","\n","df_output = pd.concat([y_test, pd.DataFrame(y_tmp, columns=['Survived'])], axis=1)\n","\n","df_output.to_csv('titanic_res.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}